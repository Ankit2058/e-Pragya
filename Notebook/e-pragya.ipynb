{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12037913,"sourceType":"datasetVersion","datasetId":7574805}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# This notebook is the first notebook of code for the project e-Pragya, this project is intented to build up from the scratch, starting from the basic encoder decoder model and going all the way to where the current Status quo of Ai stands at","metadata":{}},{"cell_type":"code","source":"!pip install pytorch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T15:55:15.169150Z","iopub.execute_input":"2025-06-01T15:55:15.169823Z","iopub.status.idle":"2025-06-01T15:55:20.674215Z","shell.execute_reply.started":"2025-06-01T15:55:15.169797Z","shell.execute_reply":"2025-06-01T15:55:20.672930Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-01T15:52:32.435631Z","iopub.execute_input":"2025-06-01T15:52:32.435925Z","iopub.status.idle":"2025-06-01T15:52:34.644959Z","shell.execute_reply.started":"2025-06-01T15:52:32.435898Z","shell.execute_reply":"2025-06-01T15:52:34.643853Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nfolder_path = '/kaggle/input/personal-notes'\ntext_list = []\n\n# Looping through all files in the folder\nfor filename in os.listdir(folder_path):\n    if filename.endswith('.txt'):\n        file_path = os.path.join(folder_path, filename)\n        with open(file_path, 'r', encoding='utf-8') as f:\n            content = f.read()\n            text_list.append(content)\n\n# the list text_data_list contains all the text data\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T16:19:38.044843Z","iopub.execute_input":"2025-06-02T16:19:38.045557Z","iopub.status.idle":"2025-06-02T16:19:38.178415Z","shell.execute_reply.started":"2025-06-02T16:19:38.045528Z","shell.execute_reply":"2025-06-02T16:19:38.177508Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"text = '\\n'.join(text_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T16:20:00.950440Z","iopub.execute_input":"2025-06-02T16:20:00.950754Z","iopub.status.idle":"2025-06-02T16:20:00.955520Z","shell.execute_reply.started":"2025-06-02T16:20:00.950729Z","shell.execute_reply":"2025-06-02T16:20:00.954583Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Total number of characteres in the input text\", len(text))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T16:20:11.118546Z","iopub.execute_input":"2025-06-02T16:20:11.118828Z","iopub.status.idle":"2025-06-02T16:20:11.124142Z","shell.execute_reply.started":"2025-06-02T16:20:11.118810Z","shell.execute_reply":"2025-06-02T16:20:11.123065Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"lets look at the first 1000 characters\", text[:1000])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T16:20:20.035413Z","iopub.execute_input":"2025-06-02T16:20:20.035697Z","iopub.status.idle":"2025-06-02T16:20:20.040195Z","shell.execute_reply.started":"2025-06-02T16:20:20.035677Z","shell.execute_reply":"2025-06-02T16:20:20.039164Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#so we have the text, now first take the unique characters from the text\n#and then put them in the list and then sort them, calaculate the length\n#list and then print all of the information","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T15:53:53.996340Z","iopub.execute_input":"2025-06-01T15:53:53.996680Z","iopub.status.idle":"2025-06-01T15:53:54.001914Z","shell.execute_reply.started":"2025-06-01T15:53:53.996656Z","shell.execute_reply":"2025-06-01T15:53:54.000677Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"char = sorted(list(set(text)))\nnumber_of_char = len(char)\nprint(''.join(char))\nprint(\"number of characters is\", number_of_char)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T16:20:50.336278Z","iopub.execute_input":"2025-06-02T16:20:50.336666Z","iopub.status.idle":"2025-06-02T16:20:50.343471Z","shell.execute_reply.started":"2025-06-02T16:20:50.336640Z","shell.execute_reply":"2025-06-02T16:20:50.342491Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"stoi = { ch:i for i,ch in enumerate(char)}\nitos = { i:ch for i,ch in enumerate(char)}\nencode = lambda s: [stoi[c] for c in s]\ndecode = lambda l: [''.join(itos[i] for i in l)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T16:20:56.417383Z","iopub.execute_input":"2025-06-02T16:20:56.417652Z","iopub.status.idle":"2025-06-02T16:20:56.423071Z","shell.execute_reply.started":"2025-06-02T16:20:56.417632Z","shell.execute_reply":"2025-06-02T16:20:56.422057Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"first i made an mapping between number and characters and then from character to numbers\nthen i created the function which returns the numbers for the given string, thus encoding\nthen i created the function which returns the characters for the given numbers, thus decoding","metadata":{}},{"cell_type":"markdown","source":"now lets convert the list of numbers into tensors, cause pytorch works in tensors","metadata":{}},{"cell_type":"code","source":"import torch\ndata = torch.tensor(encode(text),dtype=torch.long)\nprint(data.shape,data.dtype)\nprint(data[:1000])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T16:21:02.809505Z","iopub.execute_input":"2025-06-02T16:21:02.809949Z","iopub.status.idle":"2025-06-02T16:21:08.104334Z","shell.execute_reply.started":"2025-06-02T16:21:02.809924Z","shell.execute_reply":"2025-06-02T16:21:08.103540Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"now convert the data into training and validation set","metadata":{}},{"cell_type":"code","source":"n = int(0.8*len(data))\ntrain_data = data[:n]\nval_data = data[n:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T16:21:13.160835Z","iopub.execute_input":"2025-06-02T16:21:13.161741Z","iopub.status.idle":"2025-06-02T16:21:13.166458Z","shell.execute_reply.started":"2025-06-02T16:21:13.161708Z","shell.execute_reply":"2025-06-02T16:21:13.165299Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"block_size = 8\ntrain[:block_size+1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T16:22:45.074703Z","iopub.execute_input":"2025-06-02T16:22:45.075050Z","iopub.status.idle":"2025-06-02T16:22:45.082803Z","shell.execute_reply.started":"2025-06-02T16:22:45.075026Z","shell.execute_reply":"2025-06-02T16:22:45.082056Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"now lets define the context and target values, all the values are the context data while every value except for the first one becomes target, cause target is the thing our model computes after it looks at the context, its the thing that comes next,so first word isnt target cause there is no context before the first value","metadata":{}},{"cell_type":"code","source":"x = train_data[:block_size]\ny = train_data[1:block_size+1]\nfor i in range(block_size):\n    context=x[:i+1]\n    target=y[i]\n    print(f\"When the context is {context} target is {target}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T16:23:03.745482Z","iopub.execute_input":"2025-06-02T16:23:03.745821Z","iopub.status.idle":"2025-06-02T16:23:03.755509Z","shell.execute_reply.started":"2025-06-02T16:23:03.745796Z","shell.execute_reply":"2025-06-02T16:23:03.754629Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"so now create a batch of training and testing data \ngpu enable us to stact multple data into a batch and process it as a whole","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(1337)\nbatch_size = 4 # number of independent sequences processing in parallel?\nblock_size = 8 \n\ndef get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,))\n    x = torch.stack([data[i:i+block_size] for i in ix])\n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n    return x, y\n\nxb, yb = get_batch('train')\nprint('inputs:')\nprint(xb.shape)\nprint(xb)\nprint('targets:')\nprint(yb.shape)\nprint(yb)\n\nprint('----')\n\nfor b in range(batch_size): # batch dimension\n    for t in range(block_size): # time dimension\n        context = xb[b, :t+1]\n        target = yb[b,t]\n        print(f\"when input is {context.tolist()} the target: {target}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(xb) # our input to the transformer","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\ntorch.manual_seed(1337)\n\nclass BigramLanguageModel(nn.Module):\n\n    def __init__(self, vocab_size):\n        super().__init__()\n        # each token directly reads off the logits for the next token from a lookup table\n        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n\n    def forward(self, idx, targets=None):\n\n        # idx and targets are both (B,T) tensor of integers\n        logits = self.token_embedding_table(idx) # (B,T,C)\n\n        if targets is None:\n            loss = None\n        else:\n            B, T, C = logits.shape\n            logits = logits.view(B*T, C)\n            targets = targets.view(B*T)\n            loss = F.cross_entropy(logits, targets)\n\n        return logits, loss\n\n    def generate(self, idx, max_new_tokens):\n        # idx is (B, T) array of indices in the current context\n        for _ in range(max_new_tokens):\n            # get the predictions\n            logits, loss = self(idx)\n            # focus only on the last time step\n            logits = logits[:, -1, :] # becomes (B, C)\n            # apply softmax to get probabilities\n            probs = F.softmax(logits, dim=-1) # (B, C)\n            # sample from the distribution\n            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n            # append sampled index to the running sequence\n            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n        return idx\n\nm = BigramLanguageModel(vocab_size)\nlogits, loss = m(xb, yb)\nprint(logits.shape)\nprint(loss)\n\nprint(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}